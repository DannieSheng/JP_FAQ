{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c028b049",
   "metadata": {},
   "source": [
    "```\n",
    "conda install conda-forge::poppler  \n",
    "conda install conda-forge::tesseract  \n",
    "\n",
    "On Mac:  \n",
    "`brew install tesseract`  \n",
    "`brew install poppler-utils`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c20625ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudanyunsheng/miniforge3/envs/jpfaq/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hudanyunsheng/Documents/GitHub/JP_FAQ/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import difflib\n",
    "import numpy as np\n",
    "import pymupdf\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "# from unstructured_inference.models.tables import cells_to_html\n",
    "\n",
    "\n",
    "# Get the current working directory\n",
    "current_working_directory = os.getcwd()\n",
    "# Print the current working directory\n",
    "print(current_working_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68018e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_strings_similarity(str1, str2):\n",
    "    return difflib.SequenceMatcher(None, str1, str2).ratio()\n",
    "\n",
    "\n",
    "# Function to convert list of lists to HTML table\n",
    "def list_to_html_table(data):\n",
    "    html = '<table border=\"1\">\\n'\n",
    "    for row in data:\n",
    "        html += '  <tr>\\n'\n",
    "        for column in row:\n",
    "            # Replace '\\n' with '<br>'\n",
    "            column = column.replace('\\n', '<br>')\n",
    "            html += f'    <td>{column}</td>\\n'\n",
    "        html += '  </tr>\\n'\n",
    "    html += '</table>'\n",
    "    return html\n",
    "\n",
    "\n",
    "def create_markdown_table(data):\n",
    "    # Create the header row\n",
    "    markdown = '| ' + ' | '.join([cell.replace('\\n', '<br>') for cell in data[0]]) + ' |\\n'\n",
    "    # Create the separator row\n",
    "    markdown += '| ' + ' | '.join(['---'] * len(data[0])) + ' |\\n'\n",
    "    # Create the data rows\n",
    "    for row in data[1:]:\n",
    "        print(row)\n",
    "        markdown_row = '| ' + ' | '.join([cell.replace('\\n', '<br>') for cell in row]) + ' |\\n'\n",
    "        # markdown_row = '| ' + ' | '.join([cell for cell in row]) + ' |\\n'\n",
    "        markdown += markdown_row\n",
    "    return markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80a470ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_pdf = \"../data/JP Label/stelara iv Japanese PI.pdf\"\n",
    "path_pdf = \"../data/JP Label/stelara sc Japanese PI.pdf\"\n",
    "\n",
    "filename = path_pdf.split(\"/\")[-1].split(\".pdf\")[0]\n",
    "dir_partitions = \"../output/JP Label images partition/\"\n",
    "if not os.path.exists(dir_partitions):\n",
    "    os.makedirs(dir_partitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa5139c",
   "metadata": {},
   "source": [
    "#### Parse texts\n",
    "This method parse everything as texts; meanwhile, it is capable of getting the page number and physical location of special elements. However, the table parsing is not 100% confident. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b695e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "doc = pymupdf.open(path_pdf) # open a document\n",
    "for page in doc: # iterate the document pages\n",
    "    text = page.get_text() # get plain text encoded as UTF-8\n",
    "    texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e21e03f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1:\n",
      "4 tables\n",
      "Page 2:\n",
      "1 tables\n",
      "Page 3:\n",
      "2 tables\n",
      "Page 4:\n",
      "2 tables\n"
     ]
    }
   ],
   "source": [
    "tbs = {}\n",
    "bboxes = {}\n",
    "n = 1\n",
    "for page in doc:\n",
    "    tbs[f\"page {n}\"] = []\n",
    "    bboxes[f\"page {n}\"] = []\n",
    "    print(f\"Page {n}:\")\n",
    "    n_tb = 0\n",
    "    for tb in page.find_tables(vertical_strategy=\"lines_strict\", horizontal_strategy=\"lines_strict\", snap_x_tolerance=1): \n",
    "        # print(len(tb.cells))\n",
    "        n_tb += 1\n",
    "        tbs[f\"page {n}\"].append(tb.extract())\n",
    "        bboxes[f\"page {n}\"].append(tb.bbox) # x0, y0, x1, y1\n",
    "    n += 1\n",
    "    print(f\"{n_tb} tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c0c58f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into each paragraph\n",
    "text = \"\\n\".join(texts)\n",
    "result = {}\n",
    "current_key = ''\n",
    "lines = text.splitlines()\n",
    "for line in lines:\n",
    "    section_match = re.match(r'^(\\d+\\.\\s+.+)', line)\n",
    "    if section_match:\n",
    "        # current_key = line.split(' ', 1)[1]\n",
    "        current_key = section_match.group(1).strip()\n",
    "        result[current_key] = []\n",
    "    else:\n",
    "        if current_key in result:\n",
    "            result[current_key].append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "29cb63a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def match_table_to_paragraph(tables, paragraphs):\n",
    "#     matched_tables = {}\n",
    "    \n",
    "#     # Flatten paragraphs to single string for easier comparison\n",
    "#     paragraph_text = ' '.join(paragraphs)\n",
    "    \n",
    "#     for i, table in enumerate(tables):\n",
    "#         table_text = ' '.join([' '.join([cell if cell is not None else '' for cell in row]) for row in table])\n",
    "        \n",
    "#         # Check for matching keywords or phrases\n",
    "#         if any(keyword in paragraph_text for keyword in table_text.split()):\n",
    "#             matched_tables[i] = table\n",
    "    \n",
    "#     return matched_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2ef8c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_table_to_paragraph(tables, paragraphs):\n",
    "    matched_tables = []# {}\n",
    "    paragraph_text = ' '.join(paragraphs)\n",
    "    remaining_paragraph_text = paragraph_text\n",
    "\n",
    "    for table_idx, table in enumerate(tables):\n",
    "        table_texts = [cell.replace(\"\\n\", \"\") for row in table for cell in row if cell]\n",
    "        \n",
    "        # Check if all texts in the table match part of the paragraph\n",
    "        if all(any(cell in paragraph for paragraph in paragraphs) for cell in table_texts):\n",
    "            # matched_tables[table_idx] = table\n",
    "            matched_tables.append((table_idx, table))\n",
    "            \n",
    "            # Remove matched texts from the paragraph and insert placeholder\n",
    "            for cell in table_texts:\n",
    "                remaining_paragraph_text = remaining_paragraph_text.replace(cell, f\"{{Table_{table_idx}}}\")\n",
    "\n",
    "    return matched_tables, remaining_paragraph_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "88161ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_tables = dict()\n",
    "\n",
    "for pg, _tbs in tbs.items():\n",
    "    matched_tables[pg] = dict()\n",
    "    for header, paragraph in result.items():\n",
    "        matched_table, remaining_paragraph_text = match_table_to_paragraph(_tbs, paragraph)\n",
    "        if len(matched_table) > 0:\n",
    "            assert len(matched_table) == 1\n",
    "            matched_tables[pg][header] = matched_table\n",
    "            \n",
    "            # update\n",
    "            result[header] = remaining_paragraph_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "67f16c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', '5%以上', '1～5%未満', '1%未満', '頻度不明'],\n",
       " ['感染症及び\\n寄生虫症', '鼻咽頭炎', '上気道感染', '外陰腟真菌\\n感染、副鼻\\n腔炎、帯状\\n疱疹、歯肉\\n炎', ''],\n",
       " ['精神障害', '', '', 'うつ病', ''],\n",
       " ['神経系障害', '', '頭痛、浮動\\n性めまい', '', ''],\n",
       " ['呼吸器、胸\\n郭及び縦隔\\n障害', '', '咽喉頭疼痛', '鼻閉', '好酸球性肺\\n炎'],\n",
       " ['胃腸障害', '', '悪心、嘔吐', '下痢', ''],\n",
       " ['皮膚及び皮\\n下組織障害', '', '発疹、そう\\n痒症', 'ざ瘡、蕁麻\\n疹、過敏性\\n血管炎', '膿疱性乾\\n癬、乾癬性\\n紅皮症'],\n",
       " ['筋骨格系及\\nび結合組織\\n障害', '', '関節痛', '筋痛、背部\\n痛', ''],\n",
       " ['全身障害及\\nび投与局所\\n様態', '', '注射部位反\\n応、疲労', '無力症', '']]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbs['page 2'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1ba33a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = tbs['page 2'][0]\n",
    "table_texts = [cell.replace(\"\\n\", \"\") for row in table for cell in row if cell]\n",
    "paragraphs = result['11. 副作用']\n",
    "\n",
    "all(any(cell in paragraph for paragraph in paragraphs) for cell in table_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "29ec2a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5%以上',\n",
       " '1～5%未満',\n",
       " '1%未満',\n",
       " '頻度不明',\n",
       " '感染症及び寄生虫症',\n",
       " '鼻咽頭炎',\n",
       " '上気道感染',\n",
       " '外陰腟真菌感染、副鼻腔炎、帯状疱疹、歯肉炎',\n",
       " '精神障害',\n",
       " 'うつ病',\n",
       " '神経系障害',\n",
       " '頭痛、浮動性めまい',\n",
       " '呼吸器、胸郭及び縦隔障害',\n",
       " '咽喉頭疼痛',\n",
       " '鼻閉',\n",
       " '好酸球性肺炎',\n",
       " '胃腸障害',\n",
       " '悪心、嘔吐',\n",
       " '下痢',\n",
       " '皮膚及び皮下組織障害',\n",
       " '発疹、そう痒症',\n",
       " 'ざ瘡、蕁麻疹、過敏性血管炎',\n",
       " '膿疱性乾癬、乾癬性紅皮症',\n",
       " '筋骨格系及び結合組織障害',\n",
       " '関節痛',\n",
       " '筋痛、背部痛',\n",
       " '全身障害及び投与局所様態',\n",
       " '注射部位反応、疲労',\n",
       " '無力症']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e1aaa47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_table(table):\n",
    "    return [cell for row in table for cell in row if cell]\n",
    "\n",
    "def match_table_to_paragraph(tables, paragraphs):\n",
    "    matched_tables = {}\n",
    "    remaining_paragraphs = list(paragraphs)  # Make a copy of the paragraphs list\n",
    "\n",
    "    for table_idx, table in enumerate(tables):\n",
    "        table_texts = flatten_table(table)\n",
    "        table_matched = True\n",
    "        \n",
    "        for cell in table_texts:\n",
    "            if not any(cell in para for para in paragraphs):\n",
    "                table_matched = False\n",
    "                break\n",
    "        \n",
    "        if table_matched:\n",
    "            matched_tables[table_idx] = table\n",
    "            \n",
    "            # Remove matched texts from the paragraph and insert placeholder\n",
    "            for cell in table_texts:\n",
    "                remaining_paragraphs = [para.replace(cell, f\"{{Table_{table_idx}}}\") for para in remaining_paragraphs]\n",
    "\n",
    "    return matched_tables, remaining_paragraphs\n",
    "\n",
    "# Sample data\n",
    "tables = [\n",
    "    [['5%以上', '1～5%未満', '1%未満', '頻度不明', '感染症及び寄生虫症', '鼻咽頭炎', '上気道感染', '外陰腟真菌感染、副鼻腔炎、帯状疱疹、歯肉炎'],\n",
    "     ['精神障害', 'うつ病', '神経系障害', '頭痛、浮動性めまい', '呼吸器、胸郭及び縦隔障害', '咽喉頭疼痛', '鼻閉', '好酸球性肺炎'],\n",
    "     ['胃腸障害', '悪心、嘔吐', '下痢', '皮膚及び皮下組織障害', '発疹、そう痒症', 'ざ瘡、蕁麻疹、過敏性血管炎'],\n",
    "     ['膿疱性乾癬、乾癬性紅皮症', '筋骨格系及び結合組織障害', '関節痛', '筋痛、背部痛', '全身障害及び投与局所様態', '注射部位反応、疲労', '無力症']]\n",
    "]\n",
    "\n",
    "paragraphs = [\n",
    "    '次の副作用があらわれることがあるので、観察を十分に',\n",
    "    '行い、異常が認められた場合には投与を中止するなど適',\n",
    "    '切な処置を行うこと。',\n",
    "    '11.1 重大な副作用',\n",
    "    '11.1.1 アナフィラキシー（頻度不明）',\n",
    "    '発疹、蕁麻疹、血管浮腫等があらわれることがある。',\n",
    "    '11.1.2 重篤な感染症（1～5%未満）',\n",
    "    'ウイルス、細菌あるいは真菌による重篤な感染症（蜂巣',\n",
    "    '炎、憩室炎、骨髄炎、胃腸炎、肺炎及び尿路感染等）が',\n",
    "    'あらわれることがある。重篤な感染症が発現した場合に',\n",
    "    'は、感染が回復するまで本剤の投与をしないこと。',\n",
    "    '［1.1、',\n",
    "    '1.2、2.1、8.1、9.1.1参照］',\n",
    "    '11.1.3 結核（頻度不明）',\n",
    "    '結核が発現又は再活性化する可能性がある。',\n",
    "    '［1.1、1.3、',\n",
    "    '2.2、8.2、9.1.2参照］',\n",
    "    '11.1.4 間質性肺炎（頻度不明）',\n",
    "    '咳嗽、呼吸困難、発熱、肺音の異常（捻髪音）等が認め',\n",
    "    'られた場合には、速やかに胸部X線、胸部CT、血清マー',\n",
    "    'カー等の検査を実施すること。間質性肺炎が疑われた場',\n",
    "    '合には投与を中止し、副腎皮質ホルモン剤の投与等の適',\n",
    "    '切な処置を行うこと。',\n",
    "    '11.2 その他の副作用',\n",
    "    '5%以上',\n",
    "    '1～5%未満',\n",
    "    '1%未満',\n",
    "    '頻度不明',\n",
    "    '感染症及び',\n",
    "    '寄生虫症',\n",
    "    '鼻咽頭炎',\n",
    "    '上気道感染',\n",
    "    '外陰腟真菌',\n",
    "    '感染、副鼻',\n",
    "    '腔炎、帯状',\n",
    "    '疱疹、歯肉',\n",
    "    '炎',\n",
    "    '精神障害',\n",
    "    'うつ病',\n",
    "    '神経系障害',\n",
    "    '頭痛、浮動',\n",
    "    '性めまい',\n",
    "    '呼吸器、胸',\n",
    "    '郭及び縦隔',\n",
    "    '障害',\n",
    "    '咽喉頭疼痛',\n",
    "    '鼻閉',\n",
    "    '好酸球性肺',\n",
    "    '炎',\n",
    "    '胃腸障害',\n",
    "    '悪心、嘔吐',\n",
    "    '下痢',\n",
    "    '皮膚及び皮',\n",
    "    '下組織障害',\n",
    "    '発疹、そう',\n",
    "    '痒症',\n",
    "    'ざ瘡、蕁麻',\n",
    "    '疹、過敏性',\n",
    "    '血管炎',\n",
    "    '膿疱性乾',\n",
    "    '癬、乾癬性',\n",
    "    '紅皮症',\n",
    "    '筋骨格系及',\n",
    "    'び結合組織',\n",
    "    '障害',\n",
    "    '関節痛',\n",
    "    '筋痛、背部',\n",
    "    '痛',\n",
    "    '全身障害及',\n",
    "    'び投与局所',\n",
    "    '様態',\n",
    "    '注射部位反',\n",
    "    '応、疲労',\n",
    "    '無力症'\n",
    "]\n",
    "\n",
    "matched_tables, updated_paragraphs = match_table_to_paragraph(tables, paragraphs)\n",
    "\n",
    "# Print matched tables\n",
    "for idx, table in matched_tables.items():\n",
    "    print(f\"Table {idx} matches the paragraph:\")\n",
    "    for row in table:\n",
    "        print(row)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# # Print the updated paragraphs with placeholders\n",
    "# print(\"Updated Paragraph with Placeholders:\")\n",
    "# for para in updated_paragraphs:\n",
    "#     print(para)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "856a6907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3. 組成・性状'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b0df35d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: [['色・性状', '無色～淡黄色の澄明又はわずかに混濁した液'],\n",
       "  ['pH', '5.7～6.3'],\n",
       "  ['浸透圧比', '約1（生理食塩液に対する比）']]}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ae28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0463470",
   "metadata": {},
   "source": [
    "#### Parse tables (and / or images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4fdaa0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total 42 elements\n",
      "Categories of all elements are: {'CompositeElement', 'Table'}\n",
      "7 tables\n"
     ]
    }
   ],
   "source": [
    "# parse tables and images from pdf file (and save them)\n",
    "raw_pdf_elements = partition_pdf(\n",
    "    filename=path_pdf,                  # mandatory\n",
    "    strategy=\"hi_res\",                                     # mandatory to use ``hi_res`` strategy\n",
    "    extract_images_in_pdf=True,                            # mandatory to set as ``True``\n",
    "    extract_image_block_types=[\"Image\", \"Table\"],          # optional\n",
    "    extract_image_block_to_payload=False,                  # optional\n",
    "    extract_image_block_output_dir=dir_partitions + filename, #.split(\".\")[0] + \"/\",  # optional - only works when \n",
    "    chunking_strategy=\"by_title\",\n",
    "    # extract_image_block_to_payload=True\n",
    "    multipage_sections = \"False\",\n",
    "    include_page_breaks = \"False\",\n",
    "    )\n",
    "\n",
    "print(f\"In total {len(raw_pdf_elements)} elements\")\n",
    "ele_types = set([ele.category for ele in raw_pdf_elements])\n",
    "print(f\"Categories of all elements are: {ele_types}\")\n",
    "\n",
    "ele_groups = dict((key, []) for key in ele_types)\n",
    "\n",
    "for ele in raw_pdf_elements:\n",
    "    ele_groups[ele.category].append(ele)\n",
    "print(f\"{len(ele_groups['Table'])} tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cbec8103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'販売名 ステラーラ皮下注45mgシリンジ 有効成分 （1シリンジ0.5mL中） ウステキヌマブ（遺伝子組換え）45mg含有 添加剤 精製白糖38mg、L-ヒスチジン0.5mg、ポリソ ルベート80 0.02mg'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_tables_page['page 1'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3d79e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_tables = [x.to_dict() for x in ele_groups['Table']]\n",
    "info_images = [x.to_dict() for x in ele_groups['CompositeElement']]\n",
    "\n",
    "# parsed tables (and / or images) for each page\n",
    "info_tables_page = defaultdict(list)\n",
    "for info_table in info_tables:\n",
    "    pg = info_table['metadata']['page_number']\n",
    "    info_tables_page[f\"page {pg}\"].append(info_table)\n",
    "\n",
    "info_images_page = defaultdict(list)\n",
    "for info_image in info_images:\n",
    "    pg = info_table['metadata']['page_number']\n",
    "    info_images_page[f\"page {pg}\"].append(info_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f287d7",
   "metadata": {},
   "source": [
    "#### Compare string similarity between two sets of extracted tables to create a mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "79df5e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page 1': {0: [0.08108108108108109,\n",
       "   0.05235602094240838,\n",
       "   0.9809523809523809,\n",
       "   0.07453416149068323],\n",
       "  1: [0.08080808080808081, 0.07042253521126761, 0.07453416149068323, 1.0]},\n",
       " 'page 2': {0: [0.8560460652591171]},\n",
       " 'page 3': {0: [0.4217391304347826, 0.2057877813504823],\n",
       "  1: [0.026578073089700997, 0.9605263157894737]},\n",
       " 'page 4': {0: [0.8247422680412371, 0.582010582010582],\n",
       "  1: [0.6666666666666666, 0.9519230769230769]}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = dict()\n",
    "for pg, tbs_p in tbs.items():\n",
    "    info_tbs_p = info_tables_page[pg]\n",
    "    scores[pg] = dict()\n",
    "\n",
    "    # one-to-one comparison\n",
    "    for i in range(len(info_tbs_p)):\n",
    "        info_tb = info_tbs_p[i]\n",
    "        scores[pg][i] = []#dict()\n",
    "        \n",
    "        for j in range(len(tbs_p)):\n",
    "            tb_p = tbs_p[j]           \n",
    "            # scores[pg][i][j] = compare_strings_similarity(info_tb['text'], ' '.join([item for sublist in tb_p for item in sublist if item is not None]))\n",
    "            scores[pg][i].append(compare_strings_similarity(info_tb['text'], ' '.join([item for sublist in tb_p for item in sublist if item is not None])))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f9009b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page 1': {0: 2, 1: 3},\n",
       " 'page 2': {0: 0},\n",
       " 'page 3': {0: 0, 1: 1},\n",
       " 'page 4': {0: 0, 1: 1}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thres = 0.6\n",
    "mappings = dict() # for each page, from text tbs to image tbs\n",
    "for pg, score in scores.items():\n",
    "    # print(pg)\n",
    "    info_tbs_p = info_tables_page[pg]\n",
    "    tbs_p = tbs[pg]\n",
    "    mappings[pg] = dict()\n",
    "    for i in range(len(info_tbs_p)):\n",
    "        # print(scores[pg][i], np.argmax(scores[pg][i]))\n",
    "        # print(f\"\\t{info_tbs_p[i]}\")\n",
    "        # print(f\"{tbs_p[np.argmax(score[i])]}\")\n",
    "        mappings[pg][i] = np.argmax(score[i]) #if max(score[i]) >= thres else None\n",
    "mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "87d01e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty string to collect all HTML content\n",
    "html_content = \"<html><body>\"\n",
    "\n",
    "for pg, mapping in mappings.items():\n",
    "    for i, idx in mapping.items():\n",
    "        html_table = list_to_html_table(tbs[pg][idx])\n",
    "        # Add the 'pg, i, idx' text before each table\n",
    "        html_content += f\"<p>Page {pg}, table(image) {i+1}, table {idx+1}</p>\\n{html_table}\\n\"\n",
    "\n",
    "# Close the HTML tags\n",
    "html_content += \"</body></html>\"\n",
    "\n",
    "# Write the collected HTML content to a file\n",
    "with open(f\"tables_{filename}.html\", \"w\") as file:\n",
    "    file.write(html_content)\n",
    "\n",
    "print(\"HTML file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "deb53ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['〈尋常性乾癬及び関節症性乾癬〉',\n",
       " '5.1 以下のいずれかを満たす尋常性乾癬又は関節症性乾癬',\n",
       " '患者に投与すること。',\n",
       " '［1.4参照］',\n",
       " '・紫外線療法を含む既存の全身療法（生物製剤を除く）',\n",
       " 'で十分な効果が得られず、皮疹が体表面積の10%以上',\n",
       " 'に及ぶ患者。',\n",
       " '・難治性の皮疹又は関節症状を有する患者。',\n",
       " '〈クローン病〉',\n",
       " '5.2 過去の治療において、栄養療法、他の薬物療法（5-ア',\n",
       " 'ミノサリチル酸製剤、ステロイド、アザチオプリン等）',\n",
       " '等による適切な治療を行っても、疾患に起因する明らか',\n",
       " 'な臨床症状が残る場合に投与すること。',\n",
       " '［1.4参照］',\n",
       " '〈潰瘍性大腸炎〉',\n",
       " '5.3 過去の治療において、他の薬物療法（ステロイド、ア',\n",
       " 'ザチオプリン等）等による適切な治療を行っても、疾患',\n",
       " 'に起因する明らかな臨床症状が残る場合に投与すること。',\n",
       " '［1.4参照］']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['5. 効能又は効果に関連する注意']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87b95ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(info_tables_page['page 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502a38ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate HTML tables\n",
    "html_table = list_to_html_table(tbs_p[0])\n",
    "# Print the HTML table\n",
    "print(html_table)\n",
    "\n",
    "# Generate markdown tables\n",
    "md_table = create_markdown_table(tbs_p[0])\n",
    "print(md_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3ae6917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_format_1(data):\n",
    "#     # Extract the main sections\n",
    "#     main_parts = data.split(' 投与量 ')\n",
    "#     weight_part = main_parts[0].replace('患者体重 ', '')\n",
    "#     dose_part = main_parts[1]\n",
    "\n",
    "#     # Split the weight and dose parts\n",
    "#     weights = re.split(r' (?=\\d+kg)', weight_part)\n",
    "#     doses = dose_part.split(' ')\n",
    "\n",
    "#     # Combine into the structured format\n",
    "#     structured_format = [['患者体重', '投与量']]\n",
    "#     for weight, dose in zip(weights, doses):\n",
    "#         structured_format.append([weight, dose])\n",
    "\n",
    "#     return structured_format\n",
    "    \n",
    "# parse_format_1(info_tables_page[1][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e1b40eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_format_2_to_string(data):\n",
    "#     # Combine header\n",
    "#     header = f\"{data[0][0]} {data[0][1]}\"\n",
    "    \n",
    "#     # Combine the rest of the data\n",
    "#     body = ' '.join([f\"{item[0]} {item[1]}\" for item in data[1:]])\n",
    "    \n",
    "#     # Combine header and body into one string\n",
    "#     return f\"{header} {body}\"\n",
    "\n",
    "# convert_format_2_to_string(tbs['page 1'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ff930ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'| 投与量 | プラセボ | 90mg<br>8週間隔投与 | 90mg<br>12週間隔投与 |\\n| --- | --- | --- | --- |\\n| Clinical remission rate | 35.9%<br>（47/131例） | 53.5%a）<br>（68/127例） | 48.8%b）<br>（63/129例） |\\n'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d18235",
   "metadata": {},
   "source": [
    "| 投与量 | プラセボ | 90mg<br>8週間隔投与 | 90mg<br>12週間隔投与 |\n",
    "| --- | --- | --- | --- |\n",
    "| Clinical remission rate | 35.9%<br>（47/131例） | 53.5%a）<br>（68/127例） | 48.8%b）<br>（63/129例） |\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "| 投与量 | プラセボ | 90mg<br>8週間隔投与 | 90mg<br>12週間隔投与 |\n",
    "| --- | --- | --- | --- |\n",
    "| Clinical remission rate | 35.9%<br>（47/131例） | 53.5%a）<br>（68/127例） | 48.8%b）<br>（63/129例） |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a74a2570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file created: output.html\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_text_and_tables(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    html_content = \"\"\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        html_content += f\"<h2>Page {page_num + 1}</h2>\\n\"\n",
    "\n",
    "        # Extract text as HTML\n",
    "        html = page.get_text(\"html\")\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Identify and extract tables\n",
    "        for table in soup.find_all(\"table\"):\n",
    "            html_content += str(table)\n",
    "        \n",
    "        # Extract other text content\n",
    "        for block in page.get_text(\"blocks\"):\n",
    "            html_content += f\"<p>{block[4]}</p>\\n\"\n",
    "\n",
    "    return html_content\n",
    "\n",
    "def save_html(content, output_path):\n",
    "    with open(output_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(content)\n",
    "\n",
    "pdf_path = path_pdf  # Replace with your PDF file path\n",
    "output_path = \"output.html\"\n",
    "\n",
    "# Extract content from PDF and convert to HTML\n",
    "html_content = extract_text_and_tables(pdf_path)\n",
    "\n",
    "# Wrap in basic HTML structure\n",
    "html_full_content = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>PDF to HTML</title>\n",
    "</head>\n",
    "<body>\n",
    "    {html_content}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Save the HTML content to a file\n",
    "save_html(html_full_content, output_path)\n",
    "\n",
    "print(f\"HTML file created: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c627b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file created: output2.html\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pdfplumber\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_text_with_pymupdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    html_content = \"\"\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        html_content += f\"<h2>Page {page_num + 1}</h2>\\n\"\n",
    "\n",
    "        # Extract text as HTML\n",
    "        html = page.get_text(\"html\")\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Extract other text content\n",
    "        for block in page.get_text(\"blocks\"):\n",
    "            html_content += f\"<p>{block[4]}</p>\\n\"\n",
    "\n",
    "    return html_content\n",
    "\n",
    "def extract_tables_with_pdfplumber(pdf_path):\n",
    "    html_content = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            html_content += f\"<h2>Page {page_num + 1}</h2>\\n\"\n",
    "            tables = page.extract_tables()\n",
    "            for table in tables:\n",
    "                html_content += \"<table border='1'>\\n\"\n",
    "                for row in table:\n",
    "                    html_content += \"<tr>\\n\"\n",
    "                    for cell in row:\n",
    "                        cell_content = cell if cell else \"\"\n",
    "                        html_content += f\"<td>{cell_content}</td>\\n\"\n",
    "                    html_content += \"</tr>\\n\"\n",
    "                html_content += \"</table>\\n\"\n",
    "    return html_content\n",
    "\n",
    "def save_html(content, output_path):\n",
    "    with open(output_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(content)\n",
    "\n",
    "pdf_path =  path_pdf  # Replace with your PDF file path\n",
    "output_path = \"output2.html\"\n",
    "\n",
    "# Extract text and tables\n",
    "text_content = extract_text_with_pymupdf(pdf_path)\n",
    "tables_content = extract_tables_with_pdfplumber(pdf_path)\n",
    "\n",
    "# Combine content\n",
    "html_full_content = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>PDF to HTML</title>\n",
    "</head>\n",
    "<body>\n",
    "    {text_content}\n",
    "    {tables_content}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Save the HTML content to a file\n",
    "save_html(html_full_content, output_path)\n",
    "\n",
    "print(f\"HTML file created: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d058ef42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "jpfaq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
